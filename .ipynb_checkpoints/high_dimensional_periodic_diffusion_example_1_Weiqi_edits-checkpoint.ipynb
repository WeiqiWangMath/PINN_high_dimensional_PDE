{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7afa3f0",
   "metadata": {
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1673551994672,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "e7afa3f0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "np.set_printoptions(precision = 3, suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c34846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1673551995610,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "95c34846",
    "outputId": "a9cd6eeb-71f1-4012-ef03-dca5d993ee73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\weiqi\\AppData\\Local\\Temp\\ipykernel_24220\\337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0378b53",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673551996588,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "b0378b53"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "class BiasLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(BiasLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        self.bias = self.add_weight('bias',\n",
    "                                    shape=input_shape[1:],\n",
    "                                    initializer='glorot',\n",
    "                                    trainable=True)\n",
    "    def call(self, x):\n",
    "        return x + self.bias\n",
    "\n",
    "class ConstantTensorInitializer(tf.keras.initializers.Initializer):\n",
    "  \"\"\"Initializes tensors to `t`.\"\"\"\n",
    "\n",
    "  def __init__(self, t):\n",
    "    self.t = t\n",
    "\n",
    "  def __call__(self, shape, dtype=None):\n",
    "    return self.t\n",
    "\n",
    "  def get_config(self):\n",
    "    return {'t': self.t}\n",
    "\n",
    "class ConstantTensorConstraint(tf.keras.constraints.Constraint):\n",
    "  \"\"\"Constrains tensors to `t`.\"\"\"\n",
    "\n",
    "  def __init__(self, t):\n",
    "    self.t = t\n",
    "\n",
    "  def __call__(self, w):\n",
    "    return self.t\n",
    "\n",
    "  def get_config(self):\n",
    "    return {'t': self.t}\n",
    "\n",
    "# all you need to create a mask matrix M, which is a NxN identity matrix\n",
    "# and you can write a contraint like below\n",
    "class DiagonalWeight(tf.keras.constraints.Constraint):\n",
    "    \"\"\"Constrains the weights to be diagonal.\n",
    "    \"\"\"\n",
    "    def __call__(self, w):\n",
    "        N = K.int_shape(w)[-1]\n",
    "        m = K.eye(N)\n",
    "        v = w*m\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9ca3be",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673551998355,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "4d9ca3be"
   },
   "outputs": [],
   "source": [
    "def init_model(nb_hidden_layers, nb_nodes_per_layer, m_periodic, n_periodic, omega, input_dim):\n",
    "\n",
    "    # Append hidden layers\n",
    "    all_layers = []\n",
    "\n",
    "    # Initialize a feedforward neural network\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Input is two-dimensional (time + one spatial dimension)\n",
    "    input_model = tf.keras.layers.InputLayer(input_shape= (input_dim,), name='input_model')\n",
    "    model.add(input_model)\n",
    "\n",
    "    # Construct first omega matrix\n",
    "    omega_each_dim = omega*np.ones((input_dim,1))\n",
    "    Omega_matrix = np.array([])\n",
    "\n",
    "    for dim in range(input_dim):\n",
    "        Omega_dim = np.zeros((m_periodic, input_dim))\n",
    "        Omega_dim[:,dim] = omega_each_dim[dim,0]*np.ones((m_periodic,))\n",
    "        Omega_matrix = np.vstack([Omega_matrix,Omega_dim]) if Omega_matrix.size else Omega_dim\n",
    "\n",
    "    Omega = tf.Variable(Omega_matrix.T,dtype=tf.float32)\n",
    "\n",
    "    # Create first C^inf periodic layers L_p(m,n)\n",
    "    first_periodic_layer = tf.keras.layers.Dense(m_periodic*input_dim,\n",
    "                                                 activation = tf.math.cos,\n",
    "                                                 use_bias = True,\n",
    "                                                 trainable = True,\n",
    "                                                 name = 'first_periodic_layer',\n",
    "                                                 kernel_initializer = ConstantTensorInitializer(Omega),\n",
    "                                                 kernel_constraint = ConstantTensorConstraint(Omega),\n",
    "                                                 bias_initializer = 'glorot_normal')\n",
    "    all_layers.append(first_periodic_layer)\n",
    "    model.add(first_periodic_layer)\n",
    "\n",
    "    second_periodic_layer = tf.keras.layers.Dense(m_periodic*input_dim,\n",
    "                                                  activation = 'tanh',\n",
    "                                                  use_bias = True,\n",
    "                                                  trainable = True,\n",
    "                                                  name = 'second_periodic_layer',\n",
    "                                                  kernel_constraint = DiagonalWeight(),\n",
    "                                                  kernel_initializer = 'glorot_normal',\n",
    "                                                  bias_initializer = 'glorot_normal')\n",
    "    all_layers.append(second_periodic_layer)\n",
    "    model.add(second_periodic_layer)\n",
    "\n",
    "    # create the rest of the network (substitute other code here also)\n",
    "    for layer in range(nb_hidden_layers):\n",
    "        if layer == nb_hidden_layers-1:\n",
    "            layer_name = 'first_to_last_hidden_layer'\n",
    "        else:\n",
    "            layer_name = 'hidden_layer_' + str(layer)\n",
    "\n",
    "        hidden_layer = tf.keras.layers.Dense(nb_nodes_per_layer, \n",
    "                                        activation='tanh',\n",
    "                                        name=layer_name,\n",
    "                                        kernel_initializer= 'glorot_normal')\n",
    "                                        #bias_initializer= weight_bias_initializer,\n",
    "                                        #dtype=tf.float32)\n",
    "        all_layers.append(hidden_layer)\n",
    "        model.add(hidden_layer)\n",
    "\n",
    "    # Output is one-dimensional\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f2706",
   "metadata": {
    "id": "e33f2706"
   },
   "source": [
    "## high-dimensional second order equation $-\\nabla \\cdot \\left((1+\\frac{1}{4}\\sin {2\\pi x_1}\\sin {2\\pi x_2})\\nabla \\Psi\\right) + \\nu \\Psi=- 2\\pi^2 \\cos{2\\pi x_1}\\cos{4\\pi x_1}\\sin^2 {2\\pi x_2} - \\pi^2 \\sin{2\\pi x_1}\\sin{4\\pi x_1}\\cos^2 {2\\pi x_2} + 20\\pi^2(1+\\frac{1}{4}\\sin {2\\pi x_1}\\sin {2\\pi x_2})\\sin{4\\pi x_1}\\sin{4\\pi x_2} + \\nu \\sin{4\\pi x_1}\\sin{2\\pi x_2}$ with periodic BCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1b090",
   "metadata": {
    "id": "4ce1b090"
   },
   "source": [
    "## Exact solution: $\\Psi(x) = \\sin{4\\pi x_1} \\sin{2\\pi x_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265deea1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1673552001703,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "265deea1",
    "outputId": "c3ec319a-b1f1-47a8-b20d-8a80be2f5a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_periodic_layer (Dense) (None, 66)                462       \n",
      "_________________________________________________________________\n",
      "second_periodic_layer (Dense (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "hidden_layer_0 (Dense)       (None, 30)                2010      \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "first_to_last_hidden_layer ( (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 8,785\n",
      "Trainable params: 8,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_hidden_layers = 3\n",
    "nb_nodes_per_layer = 30\n",
    "\n",
    "input_dim = 6\n",
    "m_periodic = 11\n",
    "n_periodic = 30\n",
    "\n",
    "L_period = 1.0 #2*np.pi\n",
    "omega = 2*np.pi/L_period\n",
    "# Initialize model aka u_\\theta\n",
    "model5 = init_model(nb_hidden_layers, nb_nodes_per_layer, m_periodic, n_periodic, omega, input_dim)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfcbac",
   "metadata": {
    "id": "82bfcbac"
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59af2af",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673552003827,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "a59af2af"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "N = 2000\n",
    "\n",
    "nu = 0.5\n",
    "\n",
    "# Monte Carlo points in the domain\n",
    "\n",
    "input_data_MC = np.random.uniform(0 ,1, (N,input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434061cf",
   "metadata": {
    "id": "434061cf"
   },
   "source": [
    "## Define the diffusion function and its derivatives here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26b9995",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673552004586,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "f26b9995"
   },
   "outputs": [],
   "source": [
    "def diffusion_fcns(x):\n",
    "    diffusion = 1 + 1/4 * np.sin(2*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])\n",
    "    L,x_dim = np.shape(x)\n",
    "    grad_diffusion = [np.zeros_like(x[:, 0])] * x_dim\n",
    "    grad_diffusion[0] = np.pi/2 * np.cos(2*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])\n",
    "    grad_diffusion[1] = np.pi/2 * np.sin(2*np.pi*x[:, 0]) * np.cos(2*np.pi*x[:, 1])\n",
    "    return diffusion, grad_diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d000f",
   "metadata": {
    "id": "c07d000f"
   },
   "source": [
    "## Exact solution and its gradient and divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4f40d0",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673552005703,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "cc4f40d0"
   },
   "outputs": [],
   "source": [
    "# Define the exact solution\n",
    "def exact_solu(x):\n",
    "    y = np.sin(4*np.pi*np.double(x[:, 0])) * np.sin(2*np.pi*np.double(x[:, 1]))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870065bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1673552006818,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "870065bb"
   },
   "outputs": [],
   "source": [
    "# Compute the gradient and divergence of the exact solution numerically\n",
    "def exact_grad_div(x):\n",
    "    L,x_dim = np.shape(x)\n",
    "    dx = np.double(0.003)\n",
    "    gradient = [np.zeros_like(x[:, 0])] * x_dim\n",
    "    divergence = np.zeros_like(x[:, 0])\n",
    "    \n",
    "    for i in range(x_dim):\n",
    "        dx_i = np.zeros_like(x);\n",
    "        dx_i[:, i] = 1;\n",
    "        \n",
    "            \n",
    "        # six-order finite difference\n",
    "        gradient[i] = (-1/60 * exact_solu(x - 3*dx*dx_i) + 3/20 * exact_solu(x - 2*dx*dx_i) - 3/4 * exact_solu(x - dx*dx_i) + 3/4 * exact_solu(x + dx*dx_i) - 3/20 * exact_solu(x + 2*dx*dx_i) + 1/60 * exact_solu(x + 3*dx*dx_i)) / dx\n",
    "        divergence = divergence + ((1/90) * exact_solu(x - 3*dx*dx_i) -(3/20) * exact_solu(x - 2*dx*dx_i) + (3/2) * exact_solu(x - dx*dx_i) - (49/18) * exact_solu(x) + (3/2) * exact_solu(x + dx*dx_i) - (3/20) * exact_solu(x + 2*dx*dx_i) +(1/90) * exact_solu(x + 3*dx*dx_i)) / dx**2\n",
    "#         if (i == 0):\n",
    "#             print((1/90 * np.sin(4*np.pi*(x[:, 0]-3*dx)) * np.sin(2*np.pi*x[:, 1]) -3/20 * np.sin(4*np.pi*(x[:, 0]-2*dx)) * np.sin(2*np.pi*x[:, 1]) + 3/2 * np.sin(4*np.pi*(x[:, 0]-dx)) * np.sin(2*np.pi*x[:, 1]) - 49/18 * np.sin(4*np.pi*(x[:, 0])) * np.sin(2*np.pi*x[:, 1]) + 3/2 * np.sin(4*np.pi*(x[:, 0]+dx)) * np.sin(2*np.pi*x[:, 1]) - 3/20 * np.sin(4*np.pi*(x[:, 0]+2*dx)) * np.sin(2*np.pi*x[:, 1]) +1/90 * np.sin(4*np.pi*(x[:, 0]+3*dx)) * np.sin(2*np.pi*x[:, 1])) / dx**2 - (- 16 *np.pi**2 * np.sin(4*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])))\n",
    "        \n",
    "    gradient0 = 4 * np.pi * np.cos(4*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])\n",
    "    gradient1 = 2 * np.pi * np.sin(4*np.pi*x[:, 0]) * np.cos(2*np.pi*x[:, 1])\n",
    "    divergence1 = - 20 * np.pi**2 * np.sin(4*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])\n",
    "#     print(norm(divergence1-divergence))\n",
    "    \n",
    "    return gradient, divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44a59f9",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673552008543,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "e44a59f9"
   },
   "outputs": [],
   "source": [
    "def trainStep_N_dimension(x, diffusion_x, grad_diffusion_x, exact_x, exact_grad_x, exact_div_x, opt, model):\n",
    "    \n",
    "    L,x_dim = np.shape(x)\n",
    "    \n",
    "    # Outer gradient for model parameters\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # Inner gradient for first derivative of N wrt x\n",
    "        with tf.GradientTape(persistent=True) as tape1:\n",
    "            tape1.watch(x)\n",
    "            \n",
    "            # Inner inner gradient for fi derivative of N wrt x\n",
    "            with tf.GradientTape(persistent=True) as tape2:\n",
    "                tape2.watch(x)\n",
    "            \n",
    "                N = model(x)\n",
    "            \n",
    "            # Gradient of the NN\n",
    "            grad_N = tape2.gradient(N, x)\n",
    "            grad_N_i = []\n",
    "            for i in range(x_dim):\n",
    "                grad_N_i.append(grad_N[: ,i])\n",
    "        # Divergence of the NN\n",
    "        div_N = tf.zeros([L])\n",
    "        for i in range(x_dim):\n",
    "            div_N = div_N + tape1.gradient(grad_N_i[i], x)[:, i]\n",
    "        \n",
    "            \n",
    "        \n",
    "        N = tf.reshape(N, [L])\n",
    "        \n",
    "        grad_error = [np.zeros_like(x[:, 0])] * x_dim\n",
    "        \n",
    "        # Plug trial solution into ODE:\n",
    "        divergence_error = div_N - exact_div_x\n",
    "#         grad_error[0] = grad_N[:, 0] - exact_grad_x[0]\n",
    "#         grad_error[1] = grad_N[:, 1] - exact_grad_x[1]\n",
    "        N_error = N - exact_x\n",
    "        \n",
    "#         eqn = - (1 + 1/4 * np.sin(2*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])) *  divergence_error - \\\n",
    "#         (np.pi/2 * np.cos(2*np.pi*x[:, 0]) * np.sin(2*np.pi*x[:, 1])) * grad_error[0] - \\\n",
    "#         (np.pi/2 * np.sin(2*np.pi*x[:, 0]) * np.cos(2*np.pi*x[:, 1])) * grad_error[1] + nu * N_error\n",
    "        \n",
    "        eqn = - diffusion_x *  divergence_error  + nu * N_error \n",
    "        for i in range(x_dim):\n",
    "            grad_error[i] = grad_N[:, i] - exact_grad_x[i]\n",
    "            eqn = eqn - grad_diffusion_x[i] * grad_error[i]\n",
    "        \n",
    "        loss = tf.reduce_sum(tf.square(eqn)) \n",
    "        N_loss = tf.reduce_sum(tf.square(N_error))\n",
    "        gradient_loss = tf.square(grad_error[x_dim-1])\n",
    "        for i in range(x_dim-1):\n",
    "            gradient_loss = gradient_loss + tf.square(grad_error[i])\n",
    "        gradient_loss = tf.reduce_sum(gradient_loss)\n",
    "        divergence_loss = tf.reduce_sum(tf.square(divergence_error))\n",
    "        \n",
    "    # Compute the gradient of loss wrt model parameters\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # Gradient step\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "    return loss, N_loss, gradient_loss, divergence_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281e49ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673554120108,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "281e49ef"
   },
   "outputs": [],
   "source": [
    "def PINNtrain(x, epochs, model):\n",
    "    \n",
    "    # optional, use a stopping tolerance (i.e., if loss < 1e-7 then stop training early)\n",
    "    stop_tol = 1e-12\n",
    "    \n",
    "    # set the initial best loss seen so far to something large\n",
    "    best_loss = 1e12\n",
    "    best_loss_epoch = -1\n",
    "    best_weights = None\n",
    "    \n",
    "    # Define an optimizer\n",
    "    lr = tf.keras.optimizers.schedules.PolynomialDecay(0.1, epochs, 1e-4)\n",
    "    opt = keras.optimizers.Adam()\n",
    "    epoch_loss, N_loss, gradient_loss, divergence_loss = (np.zeros(epochs) for i in range(4))\n",
    "    \n",
    "    # Calculate diffusion function, forcing term at sample points x in double precision\n",
    "    diffusion_x, grad_diffusion_x = diffusion_fcns(np.double(x.numpy()))\n",
    "    exact_x = exact_solu(np.double(x.numpy()))\n",
    "    exact_grad_x, exact_div_x = exact_grad_div(np.double(x.numpy()))\n",
    "    \n",
    "    # Main training loop\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        epoch_loss[i], N_loss[i], gradient_loss[i], divergence_loss[i]  = trainStep_N_dimension(x, diffusion_x, grad_diffusion_x, exact_x, exact_grad_x, exact_div_x, opt, model)\n",
    "        \n",
    "        if (np.mod(i, 100)==0):\n",
    "          print(\"PDE loss in {}th epoch: {: 1.6e}. Last save epoch and best loss so far: {}, {: 1.6e}.\".format(i, epoch_loss[i], best_loss_epoch, best_loss))\n",
    "    \n",
    "        if (epoch_loss[i] < best_loss):\n",
    "            best_weights = model.get_weights()\n",
    "            best_loss_epoch = i\n",
    "            best_loss = epoch_loss[i]\n",
    "            #print(\"Found a new best local minimum at epoch {}: loss {: 1.6e}. Saving weights.\".format(i, epoch_loss[i]))\n",
    "            \n",
    "        if (epoch_loss[i] < stop_tol):\n",
    "            print(\"Current model has loss {: 1.6e}, lower than stopping tolerance {: 1.6e}, stopping early at epoch {}.\".format(epoch_loss[i],stop_tol,i))\n",
    "            return epoch_loss, N_loss, gradient_loss, divergence_loss\n",
    "    \n",
    "    if (best_loss < epoch_loss[i]):\n",
    "        model.set_weights(best_weights)\n",
    "        print(\"Current loss {: 1.6e}, Best loss {: 1.6e}. Restoring best model weights.\".format(epoch_loss[i],best_loss))\n",
    "    else:\n",
    "        print(\"Current loss {: 1.6e}, Best loss {: 1.6e}. Keeping current model weights.\".format(epoch_loss[i],best_loss))\n",
    "        \n",
    "    return epoch_loss, N_loss, gradient_loss, divergence_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019f2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b019f2ab",
    "outputId": "a993ffd4-2450-4966-f55e-649e9c4d752e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE loss in 0th epoch:  2.029628e+07. Last save epoch and best loss so far: -1,  1.000000e+12.\n",
      "PDE loss in 100th epoch:  1.842215e+07. Last save epoch and best loss so far: 99,  1.843603e+07.\n",
      "PDE loss in 200th epoch:  5.998830e+06. Last save epoch and best loss so far: 199,  6.088427e+06.\n",
      "PDE loss in 300th epoch:  3.599703e+05. Last save epoch and best loss so far: 299,  3.708348e+05.\n",
      "PDE loss in 400th epoch:  9.680104e+04. Last save epoch and best loss so far: 399,  9.820623e+04.\n",
      "PDE loss in 500th epoch:  5.380214e+04. Last save epoch and best loss so far: 499,  5.408205e+04.\n",
      "PDE loss in 600th epoch:  3.358154e+04. Last save epoch and best loss so far: 599,  3.375564e+04.\n",
      "PDE loss in 700th epoch:  2.313070e+04. Last save epoch and best loss so far: 699,  2.318785e+04.\n",
      "PDE loss in 800th epoch:  1.765115e+04. Last save epoch and best loss so far: 796,  1.738647e+04.\n"
     ]
    }
   ],
   "source": [
    "# train NN for Monte Carlo sample\n",
    "epochs = 10000\n",
    "PDE_loss1, N_loss1, gradient_loss1, divergence_loss1 = PINNtrain(tf.convert_to_tensor(input_data_MC, dtype = float), epochs, model5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DbjVHNePgNev",
   "metadata": {
    "id": "DbjVHNePgNev"
   },
   "source": [
    "## Loss vs. number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c168d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1673553801743,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "d3c168d4",
    "outputId": "b13a7d4b-a3e8-4b56-a973-65690ffef743"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.semilogy(range(0, epochs), PDE_loss1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9J-RXefjgZxw",
   "metadata": {
    "id": "9J-RXefjgZxw"
   },
   "source": [
    "## Errors vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faa8dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1673553805169,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "45faa8dd",
    "outputId": "4c1eaded-7cc4-42bd-fff9-9bc2bb38e3b9"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(2)\n",
    "plt.semilogy(range(0, epochs), PDE_loss1, range(0, epochs), N_loss1, range(0, epochs), gradient_loss1, range(0, epochs), divergence_loss1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['PDE','function','gradient','divergence'])\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DwjG29Omgm0h",
   "metadata": {
    "id": "DwjG29Omgm0h"
   },
   "source": [
    "## Relative $L^2$ error. (Calculate using Monte-Carlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e2c80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1673553810147,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "eb1e2c80",
    "outputId": "7309bf49-974c-45f0-a7a2-61b9a0610699"
   },
   "outputs": [],
   "source": [
    "# relative L^2 error\n",
    "input_data_MC = np.random.uniform(0 ,1, (2*N,input_dim))\n",
    "z_model = model5(input_data_MC)\n",
    "z_model = tf.reshape(z_model, [2*N])\n",
    "z_exact = np.sin(4*np.pi*input_data_MC[:, 0]) * np.sin(2*np.pi*input_data_MC[:, 1])\n",
    "error = np.sqrt(sum(np.square(z_model - z_exact)))/np.sqrt(sum(np.square(z_exact)))\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81c38f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1673553813174,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "3a81c38f",
    "outputId": "3c4e6bb8-4635-44b2-829a-16c0e229bb31"
   },
   "outputs": [],
   "source": [
    "plt.plot(z_model-z_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Z_VV1z9hNCG",
   "metadata": {
    "id": "1Z_VV1z9hNCG"
   },
   "source": [
    "## Compare the NN results with the exact solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PEpAXV_3hBW_",
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1673553831162,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "PEpAXV_3hBW_"
   },
   "outputs": [],
   "source": [
    "# Define x3,x4,x5,x6 here\n",
    "M_plot = 50\n",
    "x3, x4, x5, x6 = 0, 0.9, -0.03, 0\n",
    "\n",
    "x = np.outer(np.linspace(0,1,M_plot), np.ones(M_plot))\n",
    "y = x.copy().T\n",
    "z_true = np.sin(4*np.pi*x) * np.sin(2*np.pi*y)\n",
    "\n",
    "x = x.reshape(M_plot**2,1)\n",
    "y = y.reshape(M_plot**2,1)\n",
    "x3 = x3* np.ones((M_plot**2,1))\n",
    "x4 = x4* np.ones((M_plot**2,1))\n",
    "x5 = x5* np.ones((M_plot**2,1))\n",
    "x6 = x6* np.ones((M_plot**2,1))\n",
    "z_model = model5(np.concatenate((x, y, x3, x4, x5, x6), axis=1))\n",
    "z_model = z_model.numpy().reshape(M_plot,M_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfac4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1673553833309,
     "user": {
      "displayName": "Weiqi Wang",
      "userId": "14698951202238730823"
     },
     "user_tz": 300
    },
    "id": "d1cfac4d",
    "outputId": "a75010b8-83b1-4a52-f1d3-7cb5e0b0ef0b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = plt.axes(projection='3d')\n",
    "x = x.reshape(M_plot,M_plot)\n",
    "y = y.reshape(M_plot,M_plot)\n",
    "function_error = z_model - z_true\n",
    "ax1.plot_wireframe(x,y,function_error)\n",
    "ax1.view_init(20,45)\n",
    "ax1.set_title(\"Error original function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf35ba6",
   "metadata": {
    "id": "ccf35ba6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
